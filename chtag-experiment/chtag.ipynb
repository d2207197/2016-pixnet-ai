{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.1\n",
      "1.11.1\n",
      "2.0.9\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import json\n",
    "import gensim\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client['chpreprcs_db']\n",
    "coll = db['chpreprcs_coll']\n",
    "print(gensim.__version__)\n",
    "print(np.__version__)\n",
    "print(json.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'D', 'VC', 'Na', 'Na', 'DE', 'Na', 'PERIODCATEGORY']\n"
     ]
    }
   ],
   "source": [
    "k = 1395958  # k = 1 ~ 1395958\n",
    "_COLL_NUM_ = 1395958\n",
    "_VEC_SIZE_ = 100\n",
    "_SYN_VEC_SIZE_ = 30\n",
    "doc = coll.find_one({\"_id\": k})['syntax_label']\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, collection):\n",
    "        self.coll = collection\n",
    "    def __iter__(self):\n",
    "        for k in range(1, _COLL_NUM_ + 1):\n",
    "            doc = self.coll.find_one({\"_id\": k})\n",
    "            s = doc['sentence']\n",
    "            if len(s) > 5:\n",
    "                yield s\n",
    "class MySyntax(object):\n",
    "    def __init__(self, collection):\n",
    "        self.coll = collection\n",
    "    def __iter__(self):\n",
    "        for k in range(1, _COLL_NUM_ + 1):\n",
    "            doc = self.coll.find_one({\"_id\": k})\n",
    "            s = doc['syntax_label']\n",
    "            if len(s) > 5:\n",
    "                yield s\n",
    "sentences = MySentences(coll)\n",
    "syntax = MySyntax(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences, window = 5, min_count = 10, _VEC_SIZE_ = 100, iter = 30)\n",
    "model.save('w2v_chtag_35')\n",
    "model_syntax = gensim.models.Word2Vec(syntax, window = 3, min_count = 10, size = _SYN_VEC_SIZE_, iter = 30)\n",
    "model_syntax.save('w2v_chtag_syntax_35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-2594edcfb10f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_keys' object does not support indexing"
     ]
    }
   ],
   "source": [
    "k = model.vocab.keys()\n",
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('楊德昌', 0.5849970579147339),\n",
       " ('影壇', 0.5447032451629639),\n",
       " ('導演', 0.5381878614425659),\n",
       " ('電影', 0.5376237630844116),\n",
       " ('侯孝賢', 0.5223599076271057),\n",
       " ('動作片', 0.4982476234436035),\n",
       " ('好萊塢', 0.491036981344223),\n",
       " ('執導', 0.48953455686569214),\n",
       " ('張作驥', 0.48481354117393494),\n",
       " ('關錦鵬', 0.4823378920555115)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['張藝謀'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'UserList'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-575e9065cfab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2v_chtag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_syntax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2v_chtag_syntax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         \u001b[0;31m# update older models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'UserList'"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load('w2v_chtag')\n",
    "model_syntax = gensim.models.Word2Vec.load('w2v_chtag_syntax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def make_cloze(num):\n",
    "    if num > 1000: num = 1000\n",
    "        \n",
    "    idx = []\n",
    "    for i in range(num):\n",
    "        idx.append(round(random.uniform(1, _COLL_NUM_)))\n",
    "    idx = sorted(set(idx[: num]))\n",
    "    \n",
    "    sentences = []\n",
    "    for i in idx:\n",
    "        sentences.append(coll.find_one({\"_id\": i})['sentence'])\n",
    "    options = []\n",
    "    keys = list(model.vocab.keys())\n",
    "    nKeys = len(keys)\n",
    "    for s in sentences:\n",
    "        l = len(s)\n",
    "        idx = list(range(0, nKeys))\n",
    "        random.shuffle(idx)\n",
    "        candidate = [keys[i] for i in idx[:3]]\n",
    "#         count = 0\n",
    "#         while count < 10:\n",
    "        i = random.randint(0, l - 1)\n",
    "#             if len(s[i]) > 4 or count == 9:\n",
    "        options.append((i, [s[i]] + candidate))\n",
    "#                 break\n",
    "#             count += 1            \n",
    "    return sentences, options\n",
    "\n",
    "def cal_score(sentences, options):\n",
    "    n = len(sentences)\n",
    "    s = 0.\n",
    "    ref = 0.\n",
    "    for i in range(n):\n",
    "        b = cloze_test(sentences[i], options[i][0], options[i][1])\n",
    "        if b.argmax() == 0: s += 1.\n",
    "        if random.randint(0, 3) == 0: ref += 1.\n",
    "    return s/float(n), ref/float(n)\n",
    "\n",
    "\n",
    "def cloze_test(string, index, candidates):\n",
    "    temp = string[:]\n",
    "    del temp[index]\n",
    "    ref_vec = np.zeros(_VEC_SIZE_)\n",
    "    l = 0\n",
    "    for w in temp:\n",
    "        if w in model.vocab:\n",
    "            ref_vec += model[w]\n",
    "        l += 1        \n",
    "#     ref_vec /= float(l)\n",
    "#     ref_vec = ref_vec / np.linalg.norm(ref_vec)\n",
    "    nc = len(candidates)\n",
    "    \n",
    "    arr = np.zeros(nc)\n",
    "    for i in range(nc):\n",
    "        if candidates[i] in model.vocab:\n",
    "            cand_vec = model[candidates[i]]\n",
    "#             arr[i] = (ref_vec * cand_vec).sum()\n",
    "            arr[i] = (ref_vec * (cand_vec / np.linalg.norm(cand_vec))).sum()\n",
    "#     l, r = arr[:, j].min(), arr[:, j].max()\n",
    "#     if r > l:\n",
    "#         arr[:, j] = (arr[:, j] - l) / (r - l)\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "def make_cloze_with_syntax(num):\n",
    "    if num > 1000: num = 1000\n",
    "        \n",
    "    idx = []\n",
    "    for i in range(num):\n",
    "        idx.append(round(random.uniform(1, _COLL_NUM_)))\n",
    "    idx = sorted(set(idx[: num]))\n",
    "    \n",
    "    sentences = []\n",
    "    syntaxes = []\n",
    "    for i in idx:\n",
    "        sentences.append(coll.find_one({\"_id\": i})['sentence'])\n",
    "        syntaxes.append(coll.find_one({\"_id\": i})['syntax_label'])\n",
    "    options = []\n",
    "    keys = list(model.vocab.keys())\n",
    "    nKeys = len(keys)\n",
    "    for s in sentences:\n",
    "        l = len(s)\n",
    "        idx = list(range(0, nKeys))\n",
    "        random.shuffle(idx)\n",
    "        candidate = [keys[i] for i in idx[:3]]\n",
    "#         count = 0\n",
    "#         while count < 10:\n",
    "        i = random.randint(0, l - 1)\n",
    "#             if len(s[i]) > 4 or count == 9:\n",
    "        options.append((i, [s[i]] + candidate))\n",
    "#                 break\n",
    "#             count += 1            \n",
    "    return sentences, syntaxes, options\n",
    "\n",
    "def cloze_test2(string, syntax, index, cand_words, cand_syntaxes):\n",
    "    str_temp = string[:]\n",
    "    syn_temp = syntax[:]\n",
    "    del str_temp[index]\n",
    "    del syn_temp[index]\n",
    "    ref_vec = np.zeros(_VEC_SIZE_)\n",
    "    l = 0\n",
    "    for w in temp:\n",
    "        if w in model.vocab:\n",
    "            ref_vec += model[w]\n",
    "        l += 1\n",
    "            \n",
    "#     ref_vec /= float(l)\n",
    "#     ref_vec = ref_vec / np.linalg.norm(ref_vec)\n",
    "    nc = len(candidates)\n",
    "    \n",
    "    arr = np.zeros(nc)\n",
    "    syn_vec = np.zeros(_SYN_VEC_SIZE_)\n",
    "    for i in range(nc):\n",
    "        if candidates[i] in model.vocab:\n",
    "            cand_vec = model[candidates[i]]\n",
    "#             arr[i] = (ref_vec * cand_vec).sum()\n",
    "            arr[i] = (ref_vec * (cand_vec / np.linalg.norm(cand_vec))).sum()\n",
    "#     l, r = arr[:, j].min(), arr[:, j].max()\n",
    "#     if r > l:\n",
    "#         arr[:, j] = (arr[:, j] - l) / (r - l)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['他們', '要', '其餘', '族人', '遠遠', '的', '相隔', '{{CD}}幾', '里', '路', ',']\n",
      "(10, [',', '機組', '寂靜', '安定下來'])\n",
      "--------------------------\n",
      "2\n",
      "['就', '點頭', '答應', '讓', '她', '回家', '。']\n",
      "(5, ['回家', '放流', '耶誕', '朝聖'])\n",
      "--------------------------\n",
      "3\n",
      "['除了', '對', '殺', '人', '者', '依法', '究辦', '外', ',']\n",
      "(2, ['殺', '腸病毒', '執行長', '喜怒哀樂'])\n",
      "--------------------------\n",
      "4\n",
      "['然後', '用', '彩筆', '畫出', '各', '種', '不同', '的', '風箏', ',']\n",
      "(5, ['種', '飆出', '改', '玉春園'])\n",
      "--------------------------\n",
      "5\n",
      "['簡直', '是', '物超所值', '。']\n",
      "(1, ['是', '憂愁', '豪邁', '果皮'])\n",
      "--------------------------\n",
      "6\n",
      "['惟', '經', '分類', '後', '大致', '可', '分成', '({{CD}})', '沿街', '步道式', '開放', '空間', '、', '({{CD}})', '通路式', '開放', '空間', '、', '({{CD}})', '廣場式', '開放', '空間', '等', '{{CD}}', '大', '種類', '。']\n",
      "(13, ['({{CD}})', '濫採', '家電業', '先聲'])\n",
      "--------------------------\n",
      "7\n",
      "['但是', '在', '行文', '時', ',']\n",
      "(4, [',', '避', '潭', '{{CD}}元化'])\n",
      "--------------------------\n",
      "8\n",
      "['湖人', '全', '場', '投籃', '命中率', '{{CD}}成{{CD}}', ',']\n",
      "(0, ['湖人', '感想', '悼念', '許可'])\n",
      "--------------------------\n",
      "9\n",
      "['也', '是', '在', '白底', '上', '作畫', '的', '呈現', ',']\n",
      "(4, ['上', '國花', '鎮定劑', '社男'])\n",
      "--------------------------\n",
      "10\n",
      "['蔡某', '始', '坦承', '涉案', '。']\n",
      "(4, ['。', '邁向', '必修', '奢求'])\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "sentences, options = make_cloze(10)\n",
    "for i in range(len(options)):\n",
    "    print(i+1)\n",
    "    print('{}\\n{}\\n--------------------------'.format(sentences[i], options[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555, 0.259\n",
      "0.570, 0.239\n",
      "0.545, 0.237\n",
      "0.547, 0.257\n",
      "0.548, 0.224\n",
      "0.540, 0.257\n",
      "0.526, 0.237\n",
      "0.551, 0.259\n",
      "0.556, 0.247\n",
      "0.541, 0.253\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sentences, options = make_cloze(1000)\n",
    "    score, ref = cal_score(sentences, options)\n",
    "    print('{:.3f}, {:.3f}'.format(score, ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dfa', 'Cab', 'Dk', 'DASHCATEGORY', 'I', 'DOTCATEGORY', 'ETCCATEGORY', 'VK', 'T', 'VE', 'Neqb', 'VJ', 'SPCHANGECATEGORY', 'EXCLAMATIONCATEGORY', 'PERIODCATEGORY', 'VB', 'V_2', 'Cba', 'COMMACATEGORY', 'Nh', 'P', 'DM', 'PARENTHESISCATEGORY', 'Nb', 'VA', 'VI', 'VC', 'A', 'FW', 'Nep', 'Caa', 'SEMICOLONCATEGORY', 'VG', 'Neqa', 'Na', 'VD', 'SHI', 'Nc', 'EXCLANATIONCATEGORY', 'QUESTIONCATEGORY', 'D', 'Cbb', 'Dfb', 'VF', 'DE', 'VAC', 'Di', 'Nd', 'Dj', 'COLONCATEGORY', 'Neu', 'VCL', 'Nf', 'VHC', 'Nv', 'Ncd', 'VL', 'VH', 'neu', 'Nes', 'Da', 'Ng', 'b', 'PAUSECATEGORY']\n"
     ]
    }
   ],
   "source": [
    "print(list(model_syntax.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cab', 0.8692370653152466),\n",
       " ('Caa', 0.822738528251648),\n",
       " ('Nb', 0.6957693099975586),\n",
       " ('Na', 0.6932872533798218),\n",
       " ('Nc', 0.6587270498275757),\n",
       " ('ETCCATEGORY', 0.632373571395874),\n",
       " ('VA', 0.5940077900886536),\n",
       " ('VC', 0.5900530219078064),\n",
       " ('A', 0.5898308753967285),\n",
       " ('Nv', 0.491829514503479)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_syntax.most_similar(['PAUSECATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749464\n",
      "10\n",
      "['洋基隊', '終場', '{{CD}}', '', '比', '{{CD}}', '神奇', '演出', '大', '逆轉', ',']\n",
      "['Nb', 'Na', 'Neu', 'Caa', 'Neu', 'VH', 'VC', 'VH', 'VA', 'COMMACATEGORY']\n",
      "773498\n",
      "16\n",
      "['身', '置', '其中', '連', '坐', '在', '你', '對面', '人', '說話', '都', '', '很', '難', '聽', '清楚', ',']\n",
      "['Na', 'VC', 'Nep', 'Cbb', 'VA', 'P', 'Nh', 'Ncd', 'Na', 'VA', 'D', 'Dfa', 'VH', 'VC', 'VH', 'COMMACATEGORY']\n",
      "775038\n",
      "20\n",
      "['全球', '最', '大', '療傷', '藥品', '供應商', '{{FW}}', '&', '{{FW}}', '目前', '正', '行銷', '{{CD}}', '種', '含有', '奈米', '大小', '結晶銀', '的', '抗菌', '藥膏', ',']\n",
      "['Nc', 'Dfa', 'VH', 'VA', 'Na', 'Na', 'Nb', 'Nd', 'D', 'VCL', 'Neu', 'Nf', 'VJ', 'Na', 'Na', 'Na', 'DE', 'VH', 'Na', 'COMMACATEGORY']\n",
      "775038\n",
      "21\n",
      "['全球', '最', '大', '療傷', '藥品', '供應商', '{{FW}}', '&', '{{FW}}', '目前', '正', '行銷', '{{CD}}', '種', '含有', '奈米', '大小', '結晶銀', '的', '抗菌', '藥膏', ',']\n",
      "['Nc', 'Dfa', 'VH', 'VA', 'Na', 'Na', 'Nb', 'Nd', 'D', 'VCL', 'Neu', 'Nf', 'VJ', 'Na', 'Na', 'Na', 'DE', 'VH', 'Na', 'COMMACATEGORY']\n",
      "840658\n",
      "7\n",
      "['在', '{{FW}}', '{{FW}}', '溫暖', '的', '歌聲', '裡', ',']\n",
      "['P', 'Nb', 'VHC', 'DE', 'Na', 'Ng', 'COMMACATEGORY']\n",
      "844325\n",
      "18\n",
      "['買', '了', '{{CD}}', '架', '當時', '算是', '先進', '稀罕', '的', '{{FW}}', '{{CD}}{{FW}}', '附', '{{CD}}', '㎜{{FW}}', '{{CD}}﹒{{CD}}', '鏡頭', '的', '相機', ',']\n",
      "['VC', 'Di', 'Neu', 'Nf', 'Nd', 'VG', 'VH', 'VH', 'DE', 'Nb', 'VC', 'Neu', 'Nf', 'Neu', 'Na', 'DE', 'Na', 'COMMACATEGORY']\n",
      "926039\n",
      "34\n",
      "['「', '來', '這裏', '許願', '的', '每', '{{CD}}', '個', '病患', '──', '每', '{{CD}}', '個', '、', '沒有', '任何', '{{CD}}', '個', '例外', '──', '他們', '的', '傷痛', '全', '在', '許願', '之後', '消失', '了', '──', '完完全全', '', '的', '消失', '。']\n",
      "['PARENTHESISCATEGORY', 'D', 'Ncd', 'VA', 'DE', 'Nes', 'Neu', 'Nf', 'Na', 'DASHCATEGORY', 'Nes', 'Neu', 'Nf', 'PAUSECATEGORY', 'VJ', 'Neqa', 'Neu', 'Nf', 'Na', 'DASHCATEGORY', 'Nh', 'DE', 'Na', 'Neqa', 'P', 'VA', 'Ng', 'VA', 'Di', 'DASHCATEGORY', 'D', 'DE', 'VA', 'PERIODCATEGORY']\n",
      "926049\n",
      "14\n",
      "['任何', '的', '傷痛', '──', '任何', '', '傷痛', '──', '都', '能', '如願', '『', '消失', '』', '…']\n",
      "['Neqa', 'DE', 'Na', 'DASHCATEGORY', 'Nepa', 'Na', 'DASHCATEGORY', 'D', 'D', 'VH', 'PARENTHESISCATEGORY', 'VA', 'PARENTHESISCATEGORY', 'ETCCATEGORY']\n",
      "1001808\n",
      "9\n",
      "['獄卒', '毫不', '留情', '地', '鞭打', '', '作惡', '的', '壞人', '。']\n",
      "['Na', 'D', 'VA', 'DE', 'VC', 'VA', 'DE', 'Na', 'PERIODCATEGORY']\n",
      "1002537\n",
      "4\n",
      "['相信', '', '已', '無庸置疑', '。']\n",
      "['VK', 'D', 'VH', 'PERIODCATEGORY']\n",
      "1056833\n",
      "28\n",
      "['從', '日本人', '的', '「', '必勝', '」', '學', '、', '「', '囍', '」', '、', '「', '佛', '」', '、', '「', '愛', '」', '大量', '被', '運用到', '', '歐美人', '的', '刺青', '文化', '中', ',']\n",
      "['P', 'Na', 'DE', 'PARENTHESISCATEGORY', 'VH', 'PARENTHESISCATEGORY', 'Na', 'PAUSECATEGORY', 'PARENTHESISCATEGORY', 'FW', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'PARENTHESISCATEGORY', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'PARENTHESISCATEGORY', 'VL', 'PARENTHESISCATEGORY', 'Neqa', 'P', 'VC', 'Na', 'DE', 'Na', 'Na', 'Ng', 'COMMACATEGORY']\n",
      "1057158\n",
      "23\n",
      "['{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '', '{{FW}}', '都', '可以', '找到', '各', '種', '長短', '、', '合身度', '的', '性感', '下身', '。']\n",
      "['Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Na', 'PAUSECATEGORY', 'Nb', 'D', 'D', 'VC', 'Nes', 'Nf', 'Na', 'PAUSECATEGORY', 'Na', 'DE', 'VH', 'Na', 'PERIODCATEGORY']\n",
      "1057158\n",
      "24\n",
      "['{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '', '{{FW}}', '都', '可以', '找到', '各', '種', '長短', '、', '合身度', '的', '性感', '下身', '。']\n",
      "['Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Na', 'PAUSECATEGORY', 'Nb', 'D', 'D', 'VC', 'Nes', 'Nf', 'Na', 'PAUSECATEGORY', 'Na', 'DE', 'VH', 'Na', 'PERIODCATEGORY']\n",
      "1057368\n",
      "6\n",
      "['則', '新', '推', '{{FW}}', '', '{{FW}}', '系列', ',']\n",
      "['D', 'D', 'VC', 'Nb', 'Na', 'COMMACATEGORY']\n",
      "1057368\n",
      "7\n",
      "['則', '新', '推', '{{FW}}', '', '{{FW}}', '系列', ',']\n",
      "['D', 'D', 'VC', 'Nb', 'Na', 'COMMACATEGORY']\n",
      "1059451\n",
      "15\n",
      "['同', '{{CD}}', '時間', '姊妹台', '{{FW}}', '{{FW}}', '的', '「', '{{FW}}', '孩子王', '」', '則', '換', '了', '主持人', ',']\n",
      "['Nes', 'Neu', 'Na', 'Nc', 'Nc', 'DE', 'PARENTHESISCATEGORY', 'FW', 'Na', 'PARENTHESISCATEGORY', 'D', 'VC', 'Di', 'Na', 'COMMACATEGORY']\n",
      "1059737\n",
      "13\n",
      "['兩', '人', '結緣', '於', '酷玩', '', '樂團(', '去年', '{{CD}}月', '的', '紐約', '演唱會', '上', ',']\n",
      "['Neu', 'Na', 'VA', 'P', 'Nb', 'Na', 'Nd', 'Nd', 'DE', 'Nc', 'Na', 'Ncd', 'COMMACATEGORY']\n",
      "1063137\n",
      "14\n",
      "['{{CD}}方面', '', '借重', '當地', '的', '原料', '、', '勞力', '、', '設廠', '條件', '等', '有利', '資源', ',']\n",
      "['Cbb', 'VC', 'Nc', 'DE', 'Na', 'PAUSECATEGORY', 'Na', 'PAUSECATEGORY', 'VA', 'Na', 'Cab', 'VK', 'Na', 'COMMACATEGORY']\n",
      "1065493\n",
      "18\n",
      "['對於', '矯治', '加害人', '偏差', '行為', '及', '觀念', '所', '', '訂立', '的', '加害人', '處遇', '計畫', '卻', '只有', '{{CD}}', '件', ',']\n",
      "['P', 'VC', 'Na', 'Na', 'Na', 'Caa', 'Na', 'D', 'VC', 'DE', 'Na', 'Na', 'Na', 'D', 'D', 'Neu', 'Nf', 'COMMACATEGORY']\n",
      "1093199\n",
      "7\n",
      "['顯示', '{{CD}}', '人', '的', '傳承', '關', '係', '', '', ',']\n",
      "['VK', 'Neu', 'Na', 'DE', 'VC', 'Na', 'COMMACATEGORY']\n",
      "1093199\n",
      "8\n",
      "['顯示', '{{CD}}', '人', '的', '傳承', '關', '係', '', '', ',']\n",
      "['VK', 'Neu', 'Na', 'DE', 'VC', 'Na', 'COMMACATEGORY']\n",
      "1093199\n",
      "9\n",
      "['顯示', '{{CD}}', '人', '的', '傳承', '關', '係', '', '', ',']\n",
      "['VK', 'Neu', 'Na', 'DE', 'VC', 'Na', 'COMMACATEGORY']\n",
      "1119369\n",
      "16\n",
      "['新版', '的', '{{FW}}', '', '{{FW}}', '.', '{{FW}}', '可以', '在', '{{FW}}', '上', '的', '{{FW}}', '{{FW}}', '可以', '找到', '。']\n",
      "['Na', 'DE', 'FW', 'FW', 'DOTCATEGORY', 'FW', 'D', 'P', 'FW', 'Ncd', 'DE', 'FW', 'FW', 'D', 'VC', 'PERIODCATEGORY']\n",
      "1168736\n",
      "3\n",
      "['。', '', '在', '短短']\n",
      "['PERIODCATEGORY', 'P', 'VH']\n",
      "1193660\n",
      "12\n",
      "['{{CD}}夫莫敵', '這', '是', '喬治', '‧', '華盛頓', '大', '將軍', '', '戰事', '失利', '後', ',']\n",
      "['VH', 'Nep', 'SHI', 'Nb', 'PERIODCATEGORY', 'Nb', 'VH', 'Na', 'Na', 'VH', 'Ng', 'COMMACATEGORY']\n",
      "1195395\n",
      "14\n",
      "['那', '時候', '侯孝賢', '早', '就', '拍出', '「', '童年', '往事', '」', '、', '', '', '」', ',']\n",
      "['Nep', 'Na', 'Nb', 'D', 'D', 'VC', 'PARENTHESISCATEGORY', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'COMMACATEGORY']\n",
      "1199895\n",
      "37\n",
      "['其', '股權', '結構', '是', '楊張美智', '(', '楊天生', '夫人', ')', '、', '郭政權', '(', '長{{CD}}', '實業', '代表', ')', '、', '王財旺', '(', '長{{CD}}', '實業', '代表', ')', '、', '簡肇涵', '(', '長{{CD}}', '實業', '代表', ')', '均', '分別', '持有', '泛亞', '股權', '{{CD}}.', '', '{{CD}}%', ',']\n",
      "['Nep', 'Na', 'Na', 'SHI', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'D', 'D', 'VJ', 'Nb', 'Na', 'Neqa', 'COMMACATEGORY']\n",
      "1199895\n",
      "38\n",
      "['其', '股權', '結構', '是', '楊張美智', '(', '楊天生', '夫人', ')', '、', '郭政權', '(', '長{{CD}}', '實業', '代表', ')', '、', '王財旺', '(', '長{{CD}}', '實業', '代表', ')', '、', '簡肇涵', '(', '長{{CD}}', '實業', '代表', ')', '均', '分別', '持有', '泛亞', '股權', '{{CD}}.', '', '{{CD}}%', ',']\n",
      "['Nep', 'Na', 'Na', 'SHI', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'D', 'D', 'VJ', 'Nb', 'Na', 'Neqa', 'COMMACATEGORY']\n"
     ]
    }
   ],
   "source": [
    "class Word2Syn(object):\n",
    "    def __init__(self, word_set, syn_set):\n",
    "        import numpy as np\n",
    "        import json\n",
    "        self.word_set = word_set\n",
    "        self.syn_set = syn_set\n",
    "\n",
    "        lw = len(word_set)\n",
    "        ls = len(syn_set)\n",
    "        word_idx = {}\n",
    "        for i in range(lw):\n",
    "            word_idx[word_set[i]] = i\n",
    "        with open('word_idx.json', 'w') as fp:\n",
    "            json.dump(word_idx, fp)\n",
    "        syn_idx = {}\n",
    "        for i in range(ls):\n",
    "            syn_idx[syn_set[i]] = i\n",
    "        with open('syn_idx.json', 'w') as fp:\n",
    "            json.dump(syn_idx, fp)\n",
    "        self.word_idx = word_idx\n",
    "        self.syn_idx = syn_idx\n",
    "        self.word_syn_mapping = np.zeros((lw, ls))\n",
    "    def generate(self, coll):\n",
    "        import numpy as np\n",
    "        for i in range(1, _COLL_NUM_ + 1):\n",
    "            sen = coll.find_one({\"_id\": i})['sentence']\n",
    "            syn = coll.find_one({\"_id\": i})['syntax_label']\n",
    "            l = len(sen)\n",
    "            for j in range(l):\n",
    "                try:\n",
    "                    if (sen[j] in self.word_idx) and (syn[j] in self.syn_idx):\n",
    "                        self.word_syn_mapping[self.word_idx[sen[j]], self.syn_idx[syn[j]]] += 1\n",
    "                except:\n",
    "                    print(i)\n",
    "                    print(j)\n",
    "                    print(sen)\n",
    "                    print(syn)\n",
    "        np.save('w2s_mapping', self.word_syn_mapping)\n",
    "\n",
    "w2s = Word2Syn(list(model.vocab), list(model_syntax.vocab))\n",
    "w2s.generate(coll)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "i = 1059451\n",
    "sen = coll.find_one({\"_id\": i})['sentence']\n",
    "syn = coll.find_one({\"_id\": i})['syntax_label']\n",
    "print(len(sen))\n",
    "print(len(syn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d73802199cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word_idx.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mword_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3333\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "word_syn_mapping = np.load('w2s_mapping.npy')\n",
    "with open('word_idx.json', 'r') as fp:\n",
    "    word_idx = json.load(fp)\n",
    "word = list(model.vocab)\n",
    "i = 3333\n",
    "print(word[i])\n",
    "print(word_idx[word[i]])\n",
    "word_syn_mapping[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
