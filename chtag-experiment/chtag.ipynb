{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.1\n",
      "1.11.1\n",
      "2.0.9\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import json\n",
    "import gensim\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client['chpreprcs_db']\n",
    "coll = db['chpreprcs_coll']\n",
    "print(gensim.__version__)\n",
    "print(np.__version__)\n",
    "print(json.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '不禁', '對', '山西', '商人', '深深', '地', '敬佩', '起來', '。']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8af89418ae4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "k = 12938  # k = 1 ~ 1395958\n",
    "_COLL_NUM_ = 1395958\n",
    "_VEC_SIZE_ = 100\n",
    "_SYN_VEC_SIZE_ = 30\n",
    "doc = coll.find_one({\"_id\": k})['sentence']\n",
    "print(doc)\n",
    "index = 4\n",
    "a = model[doc[index + 1]]\n",
    "b = model[doc[index - 1]]\n",
    "c = model[doc[index + 2]]\n",
    "d = model[doc[index - 2]]\n",
    "print('\\n')\n",
    "print(model.most_similar([a + b + c + d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, collection):\n",
    "        self.coll = collection\n",
    "    def __iter__(self):\n",
    "        for k in range(1, _COLL_NUM_ + 1):\n",
    "            doc = self.coll.find_one({\"_id\": k})\n",
    "            s = doc['sentence']\n",
    "            if len(s) > 5:\n",
    "                yield s\n",
    "class MySyntax(object):\n",
    "    def __init__(self, collection):\n",
    "        self.coll = collection\n",
    "    def __iter__(self):\n",
    "        for k in range(1, _COLL_NUM_ + 1):\n",
    "            doc = self.coll.find_one({\"_id\": k})\n",
    "            s = doc['syntax_label']\n",
    "            if len(s) > 5:\n",
    "                yield s\n",
    "sentences = MySentences(coll)\n",
    "syntax = MySyntax(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = gensim.models.Word2Vec(sentences, window = 5, min_count = 10, size = _VEC_SIZE_, iter = 30)\n",
    "# model.save('w2v_chtag_35')\n",
    "# model_syntax = gensim.models.Word2Vec(syntax, window = 3, min_count = 10, size = _SYN_VEC_SIZE_, iter = 30)\n",
    "# model_syntax.save('w2v_chtag_syntax_35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Word2Vec.train of <gensim.models.word2vec.Word2Vec object at 0x7f5f895449e8>>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('楊德昌', 0.6508117914199829), ('張作驥', 0.5904040932655334), ('瑪丹娜', 0.5871766209602356), ('音樂劇', 0.5689635276794434), ('阿呆', 0.568121612071991), ('王家衛', 0.5637759566307068), ('張毅', 0.5585370659828186), ('電視劇', 0.5552148818969727), ('鄭秀文', 0.5549250841140747), ('港劇', 0.5493459105491638)]\n",
      "[('COMMACATEGORY', 0.8969951272010803), ('SEMICOLONCATEGORY', 0.828833818435669), ('D', 0.7599872946739197), ('Cbb', 0.6997944116592407), ('Na', 0.6980289816856384), ('Neqa', 0.6058214902877808), ('VH', 0.5926657915115356), ('Caa', 0.5728498101234436), ('A', 0.5615950226783752), ('QUESTIONCATEGORY', 0.5482258796691895)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(['張藝謀']))\n",
    "print(model_syntax.most_similar(['PERIODCATEGORY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('w2v_chtag_35')\n",
    "model_syntax = gensim.models.Word2Vec.load('w2v_chtag_syntax_35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def make_cloze(num):\n",
    "    if num > 1000: num = 1000\n",
    "        \n",
    "    idx = []\n",
    "    for i in range(num):\n",
    "        idx.append(round(random.uniform(1, _COLL_NUM_)))\n",
    "    idx = sorted(set(idx[: num]))\n",
    "    \n",
    "    sentences = []\n",
    "    for i in idx:\n",
    "        sentences.append(coll.find_one({\"_id\": i})['sentence'])\n",
    "    options = []\n",
    "    keys = list(model.vocab.keys())\n",
    "    nKeys = len(keys)\n",
    "    for s in sentences:\n",
    "        l = len(s)\n",
    "        idx = list(range(0, nKeys))\n",
    "        random.shuffle(idx)\n",
    "        candidate = [keys[i] for i in idx[:3]]\n",
    "#         count = 0\n",
    "#         while count < 10:\n",
    "        i = random.randint(0, l - 1)\n",
    "#             if len(s[i]) > 4 or count == 9:\n",
    "        options.append((i, [s[i]] + candidate))\n",
    "#                 break\n",
    "#             count += 1            \n",
    "    return sentences, options\n",
    "\n",
    "def cal_score(sentences, options):\n",
    "    n = len(sentences)\n",
    "    s = 0.\n",
    "    ref = 0.\n",
    "    for i in range(n):\n",
    "        b = cloze_test(sentences[i], options[i][0], options[i][1])\n",
    "        if b.argmax() == 0: s += 1.\n",
    "        if random.randint(0, 3) == 0: ref += 1.\n",
    "    return s/float(n), ref/float(n)\n",
    "\n",
    "\n",
    "def cloze_test(string, index, candidates):\n",
    "    temp = string[:]\n",
    "    del temp[index]\n",
    "    ref_vec = np.zeros(_VEC_SIZE_)\n",
    "    l = 0\n",
    "    for w in temp:\n",
    "        if w in model.vocab:\n",
    "            ref_vec += model[w]\n",
    "        l += 1        \n",
    "#     ref_vec /= float(l)\n",
    "#     ref_vec = ref_vec / np.linalg.norm(ref_vec)\n",
    "    nc = len(candidates)\n",
    "    \n",
    "    arr = np.zeros(nc)\n",
    "    for i in range(nc):\n",
    "        if candidates[i] in model.vocab:\n",
    "            cand_vec = model[candidates[i]]\n",
    "#             arr[i] = (ref_vec * cand_vec).sum()\n",
    "            arr[i] = (ref_vec * (cand_vec / np.linalg.norm(cand_vec))).sum()\n",
    "#     l, r = arr[:, j].min(), arr[:, j].max()\n",
    "#     if r > l:\n",
    "#         arr[:, j] = (arr[:, j] - l) / (r - l)\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "def make_cloze_with_syntax(num):\n",
    "    if num > 1000: num = 1000\n",
    "        \n",
    "    idx = []\n",
    "    for i in range(num):\n",
    "        idx.append(round(random.uniform(1, _COLL_NUM_)))\n",
    "    idx = sorted(set(idx[: num]))\n",
    "    \n",
    "    SenSyn = []\n",
    "    for i in idx:\n",
    "        sen = coll.find_one({\"_id\": i})['sentence']\n",
    "        syn = coll.find_one({\"_id\": i})['syntax_label']\n",
    "        l = len(sen)\n",
    "        if l == len(syn) and l > 5:\n",
    "            SenSyn.append((sen, syn))\n",
    "        \n",
    "    Options = []\n",
    "    keys = list(model.vocab.keys())\n",
    "    nKeys = len(keys)\n",
    "    for ss in SenSyn: # ss[0]:sen, ss[1]:syn\n",
    "        l = len(ss[0])\n",
    "        idx = list(range(0, nKeys))\n",
    "        random.shuffle(idx)\n",
    "        candidate = [keys[i] for i in idx[:3]]\n",
    "#         count = 0\n",
    "#         while count < 10:\n",
    "        i = random.randint(0, l - 1)\n",
    "#             if len(s[i]) > 4 or count == 9:\n",
    "        Options.append((i, [ss[0][i]] + candidate))\n",
    "#                 break\n",
    "#             count += 1            \n",
    "    return SenSyn, Options\n",
    "\n",
    "def cloze_test2(string, syntax, index, cand_words):\n",
    "    str_temp = string[:]\n",
    "    syn_temp = syntax[:]\n",
    "    del str_temp[index]\n",
    "    del syn_temp[index]\n",
    "    word_vec = np.zeros(_VEC_SIZE_)\n",
    "    l = 0\n",
    "    for w in str_temp:\n",
    "        if w in model.vocab:\n",
    "            word_vec += model[w]\n",
    "        l += 1\n",
    "    \n",
    "    syn_vec = np.zeros(_SYN_VEC_SIZE_)\n",
    "    l = 0\n",
    "    for s in syn_temp:\n",
    "        if s in model_syntax.vocab:\n",
    "            syn_vec += model_syntax[s]\n",
    "        l += 1  \n",
    "    \n",
    "    print(string)\n",
    "    print(syntax)\n",
    "    print(index)\n",
    "    print(cand_words)\n",
    "    print(mapW2S.map_w2s(cand_words))\n",
    "#     ref_vec /= float(l)\n",
    "#     ref_vec = ref_vec / np.linalg.norm(ref_vec)\n",
    "    nc = len(cand_words)    \n",
    "    word_score = np.zeros(nc)\n",
    "    \n",
    "    for i in range(nc):\n",
    "        if cand_words[i] in model.vocab:\n",
    "            cand_vec = model[cand_words[i]]\n",
    "            word_score[i] = (word_vec * (cand_vec / np.linalg.norm(cand_vec))).sum()\n",
    "    print(word_score)\n",
    "    try:\n",
    "        a = model_syntax[syntax[index + 1]]\n",
    "        b = model_syntax[syntax[index - 1]]\n",
    "        c = model_syntax[syntax[index + 2]]\n",
    "        d = model_syntax[syntax[index - 2]]\n",
    "        print('\\n')\n",
    "        s = model_syntax.most_similar(positive=[a + b + c + d])\n",
    "        s = [x[0] for x in s]\n",
    "        print(s)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['在', '齋月', '頌', '讀', '、', '{{CD}}', '天', '正好', '讀', '{{CD}}', '卷', ',']\n",
      "['P', 'Nd', 'VC', 'VC', 'PAUSECATEGORY', 'Neu', 'Nf', 'Da', 'VC', 'Neu', 'Nf', 'COMMACATEGORY']\n",
      "9\n",
      "['{{CD}}', '工業', '犯規', '古蹟']\n",
      "{'工業': {'Na': 1365.0}, '犯規': {'Nv': 3.0, 'VA': 38.0}, '{{CD}}': {'A': 1.0, 'Nep': 2.0, 'Nc': 36.0, 'Cbb': 1816.0, 'VC': 4.0, 'Nb': 823.0, 'Neqa': 118.0, 'Nes': 5.0, 'VB': 4.0, 'PERIODCATEGORY': 1.0, 'Na': 76.0, 'Nd': 2625.0, 'VH': 62.0, 'D': 7990.0, 'Neu': 203846.0, 'Dfb': 13.0, 'FW': 401.0, 'Nf': 3.0, 'neu': 414.0, 'DM': 1.0, 'Di': 189.0}, '古蹟': {'Na': 415.0}}\n",
      "[ 17.96525334  -8.91354979  -1.18152484   1.36981799]\n",
      "\n",
      "\n",
      "['Nf', 'COMMACATEGORY', 'Da', 'PERIODCATEGORY', 'SEMICOLONCATEGORY', 'Na', 'P', 'VC', 'Ng', 'VG']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_syn, options = make_cloze_with_syntax(1)\n",
    "for i in range(len(options)):\n",
    "    cloze_test2(sen_syn[i][0], sen_syn[i][1], options[i][0], options[i][1])\n",
    "    print('\\n')\n",
    "# for i in range(len(options)):\n",
    "#     print(i+1)\n",
    "#     print('{}\\n{}\\n{}\\n--------------------------'.format(sen_syn[i][0], sen_syn[i][1], options[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sentences, options = make_cloze(1000)\n",
    "    score, ref = cal_score(sentences, options)\n",
    "    print('{:.3f}, {:.3f}'.format(score, ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMMACATEGORY', 'VC', 'EXCLAMATIONCATEGORY', 'VL', 'VAC', 'VI', 'Nh', 'D', 'DASHCATEGORY', 'VD', 'Dj', 'Di', 'Cba', 'Nep', 'COLONCATEGORY', 'SPCHANGECATEGORY', 'VF', 'Na', 'Da', 'VB', 'PERIODCATEGORY', 'Neqa', 'I', 'DM', 'DOTCATEGORY', 'Dk', 'Dfb', 'FW', 'VA', 'SEMICOLONCATEGORY', 'DE', 'SHI', 'EXCLANATIONCATEGORY', 'ETCCATEGORY', 'Nv', 'VHC', 'Neqb', 'P', 'b', 'Nd', 'Caa', 'Nf', 'Neu', 'VG', 'PARENTHESISCATEGORY', 'neu', 'Nes', 'A', 'VCL', 'VJ', 'Cab', 'Nc', 'VK', 'PAUSECATEGORY', 'V_2', 'QUESTIONCATEGORY', 'T', 'Ng', 'VE', 'VH', 'Nb', 'Dfa', 'Ncd', 'Cbb']\n"
     ]
    }
   ],
   "source": [
    "print(list(model_syntax.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Word2Syn(object):\n",
    "    def __init__(self, word_set, syn_set):\n",
    "        import numpy as np\n",
    "        import json\n",
    "        self.word_set = word_set\n",
    "        self.syn_set = syn_set\n",
    "\n",
    "        lw = len(word_set)\n",
    "        ls = len(syn_set)\n",
    "        word_idx = {}\n",
    "        for i in range(lw):\n",
    "            word_idx[word_set[i]] = i\n",
    "        with open('word_idx.json', 'w') as fp:\n",
    "            json.dump(word_idx, fp)\n",
    "        syn_idx = {}\n",
    "        for i in range(ls):\n",
    "            syn_idx[syn_set[i]] = i\n",
    "        with open('syn_idx.json', 'w') as fp:\n",
    "            json.dump(syn_idx, fp)\n",
    "        self.word_idx = word_idx\n",
    "        self.syn_idx = syn_idx\n",
    "        self.word_syn_mapping = np.zeros((lw, ls))\n",
    "    def generate(self, coll):\n",
    "        import numpy as np\n",
    "        for i in range(1, _COLL_NUM_ + 1):\n",
    "            sen = coll.find_one({\"_id\": i})['sentence']\n",
    "            syn = coll.find_one({\"_id\": i})['syntax_label']\n",
    "            l = len(sen)\n",
    "            if l == len(syn):\n",
    "                for j in range(l):\n",
    "                    try:\n",
    "                        if (sen[j] in self.word_idx) and (syn[j] in self.syn_idx):\n",
    "                            self.word_syn_mapping[self.word_idx[sen[j]], self.syn_idx[syn[j]]] += 1\n",
    "                    except:\n",
    "                        print(i)\n",
    "                        print(j)\n",
    "                        print(sen)\n",
    "                        print(syn)\n",
    "                        print('--------------------')\n",
    "            else:\n",
    "                print(i)\n",
    "                print(sen)\n",
    "                print(syn)\n",
    "                print('******************')\n",
    "        np.save('w2s_mapping', self.word_syn_mapping)\n",
    "\n",
    "w2s = Word2Syn(list(model.vocab), list(model_syntax.vocab))\n",
    "w2s.generate(coll)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "i = 1059451\n",
    "sen = coll.find_one({\"_id\": i})['sentence']\n",
    "syn = coll.find_one({\"_id\": i})['syntax_label']\n",
    "print(len(sen))\n",
    "print(len(syn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'了': {'VK': 1.0, 'DE': 7.0, 'VJ': 51.0, 'VC': 14.0, 'VF': 1.0, 'T': 18533.0, 'VA': 1.0, 'Di': 62757.0}, '買': {'VC': 2419.0, 'VB': 1.0, 'Nv': 2.0}, '架': {'VC': 46.0, 'D': 3.0, 'Na': 49.0, 'Nf': 322.0, 'VA': 1.0}, '的': {'D': 1.0, 'Na': 6.0, 'T': 20697.0, 'Ng': 4.0, 'VE': 1.0, 'VC': 1.0, 'FW': 1.0, 'Nf': 1.0, 'DE': 561136.0, 'Ncd': 1.0, 'Di': 1.0}, '當時': {'Nd': 3554.0}, '先進': {'VH': 520.0, 'Na': 31.0}, '稀罕': {'VH': 11.0, 'VJ': 6.0}, '{{CD}}': {'A': 1.0, 'Nep': 2.0, 'Nc': 36.0, 'Cbb': 1816.0, 'VC': 4.0, 'Nb': 823.0, 'Neqa': 118.0, 'Nes': 5.0, 'VB': 4.0, 'PERIODCATEGORY': 1.0, 'Na': 76.0, 'Nd': 2625.0, 'VH': 62.0, 'D': 7990.0, 'Neu': 203846.0, 'Dfb': 13.0, 'FW': 401.0, 'Nf': 3.0, 'neu': 414.0, 'DM': 1.0, 'Di': 189.0}, '算是': {'VG': 761.0}}\n"
     ]
    }
   ],
   "source": [
    "class MapW2S(object):\n",
    "    def __init__(self):\n",
    "        word_syn_mapping = np.load('w2s_mapping.npy')\n",
    "        WORD_LEN, SYN_LEN = word_syn_mapping.shape\n",
    "        with open('word_idx.json', 'r') as fp:\n",
    "            word_idx = json.load(fp)\n",
    "        with open('syn_idx.json', 'r') as fp:\n",
    "            syn_idx = json.load(fp)\n",
    "        word = ['abc' for i in range(WORD_LEN)]\n",
    "        syn = ['abc' for i in range(SYN_LEN)]\n",
    "        for w in word_idx:\n",
    "            word[word_idx[w]] = w\n",
    "        for s in syn_idx:\n",
    "            syn[syn_idx[s]] = s\n",
    "        self.word = word\n",
    "        self.word_idx = word_idx\n",
    "        self.syntax = syn\n",
    "        self.syntax_idx = syn_idx\n",
    "        self.mapping = word_syn_mapping\n",
    "    \n",
    "    def get_words(self, idx_list):\n",
    "        return [self.word[i] for i in idx_list]\n",
    "    def get_syntax(self, idx_list):\n",
    "        return [self.syntax[i] for i in idx_list]\n",
    "\n",
    "    def map_w2s(self, w_list):\n",
    "        result = {}\n",
    "        for w in w_list:\n",
    "            syn = {}\n",
    "            isyn = [x[0] for x in np.argwhere(self.mapping[self.word_idx[w], :] > 0)]\n",
    "            for i in isyn:\n",
    "                syn[self.syntax[i]] = self.mapping[self.word_idx[w], i]\n",
    "            result[w] = syn\n",
    "        return result\n",
    "\n",
    "mapW2S = MapW2S()\n",
    "l = mapW2S.map_w2s(['買', '了', '{{CD}}', '架', '當時', '算是', '先進', '稀罕', '的'])\n",
    "print(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Nc', 0.8085162043571472),\n",
       " ('COMMACATEGORY', 0.8062970042228699),\n",
       " ('Caa', 0.7769955396652222),\n",
       " ('PERIODCATEGORY', 0.76839280128479),\n",
       " ('Na', 0.7463722229003906),\n",
       " ('A', 0.7328353524208069),\n",
       " ('SEMICOLONCATEGORY', 0.7314806580543518),\n",
       " ('DE', 0.7139890193939209),\n",
       " ('Ng', 0.663489043712616),\n",
       " ('Ncd', 0.6585845947265625)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model_syntax['PERIODCATEGORY']\n",
    "a = a / a.sum()\n",
    "b = model_syntax['Ng']\n",
    "b = b / b.sum()\n",
    "c = model_syntax['Nc']\n",
    "c = c / c.sum()\n",
    "d = model_syntax['DE']\n",
    "d = d / d.sum()\n",
    "print(c.sum())\n",
    "print(d.sum())\n",
    "model_syntax.most_similar([1 * (a + b + c + d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_syn_mapping[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "775038\n",
    "['全球', '最', '大', '療傷', '藥品', '供應商', '{{FW}}', '&', '{{FW}}', '目前', '正', '行銷', '{{CD}}', '種', '含有', '奈米', '大小', '結晶銀', '的', '抗菌', '藥膏', ',']\n",
    "['Nc', 'Dfa', 'VH', 'VA', 'Na', 'Na', 'Nb', 'Nd', 'D', 'VCL', 'Neu', 'Nf', 'VJ', 'Na', 'Na', 'Na', 'DE', 'VH', 'Na', 'COMMACATEGORY']\n",
    "******************\n",
    "840658\n",
    "['在', '{{FW}}', '{{FW}}', '溫暖', '的', '歌聲', '裡', ',']\n",
    "['P', 'Nb', 'VHC', 'DE', 'Na', 'Ng', 'COMMACATEGORY']\n",
    "******************\n",
    "844325\n",
    "['買', '了', '{{CD}}', '架', '當時', '算是', '先進', '稀罕', '的', '{{FW}}', '{{CD}}{{FW}}', '附', '{{CD}}', '㎜{{FW}}', '{{CD}}﹒{{CD}}', '鏡頭', '的', '相機', ',']\n",
    "['VC', 'Di', 'Neu', 'Nf', 'Nd', 'VG', 'VH', 'VH', 'DE', 'Nb', 'VC', 'Neu', 'Nf', 'Neu', 'Na', 'DE', 'Na', 'COMMACATEGORY']\n",
    "******************\n",
    "1057158\n",
    "['{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '、', '{{FW}}', '{{FW}}', '都', '可以', '找到', '各', '種', '長短', '、', '合身度', '的', '性感', '下身', '。']\n",
    "['Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Nb', 'PAUSECATEGORY', 'Na', 'PAUSECATEGORY', 'Nb', 'D', 'D', 'VC', 'Nes', 'Nf', 'Na', 'PAUSECATEGORY', 'Na', 'DE', 'VH', 'Na', 'PERIODCATEGORY']\n",
    "******************\n",
    "1057368\n",
    "['則', '新', '推', '{{FW}}', '{{FW}}', '系列', ',']\n",
    "['D', 'D', 'VC', 'Nb', 'Na', 'COMMACATEGORY']\n",
    "******************\n",
    "1059451\n",
    "['同', '{{CD}}', '時間', '姊妹台', '{{FW}}', '{{FW}}', '的', '「', '{{FW}}', '孩子王', '」', '則', '換', '了', '主持人', ',']\n",
    "['Nes', 'Neu', 'Na', 'Nc', 'Nc', 'DE', 'PARENTHESISCATEGORY', 'FW', 'Na', 'PARENTHESISCATEGORY', 'D', 'VC', 'Di', 'Na', 'COMMACATEGORY']\n",
    "******************\n",
    "1093199\n",
    "['顯示', '{{CD}}', '人', '的', '傳承', '關', '係', ',']\n",
    "['VK', 'Neu', 'Na', 'DE', 'VC', 'Na', 'COMMACATEGORY']\n",
    "******************\n",
    "1195395\n",
    "['那', '時候', '侯孝賢', '早', '就', '拍出', '「', '童年', '往事', '」', '、', '」', ',']\n",
    "['Nep', 'Na', 'Nb', 'D', 'D', 'VC', 'PARENTHESISCATEGORY', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'COMMACATEGORY']\n",
    "******************\n",
    "1199895\n",
    "['其', '股權', '結構', '是', '楊張美智', '(', '楊天生', '夫人', ')', '、', '郭政權', '(', '長{{CD}}', '實業', '代表', ')', '、', '王財旺', '(', '長{{CD}}', '實業', '代表', ')', '、', '簡肇涵', '(', '長{{CD}}', '實業', '代表', ')', '均', '分別', '持有', '泛亞', '股權', '{{CD}}.', '{{CD}}%', ',']\n",
    "['Nep', 'Na', 'Na', 'SHI', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'Nb', 'PARENTHESISCATEGORY', 'Nb', 'Na', 'Na', 'PARENTHESISCATEGORY', 'D', 'D', 'VJ', 'Nb', 'Na', 'Neqa', 'COMMACATEGORY']\n",
    "******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
