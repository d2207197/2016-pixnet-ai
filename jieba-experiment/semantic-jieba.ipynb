{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import jieba, gensim, re, sqlite3, os\n",
    "import jieba.posseg as pseg\n",
    "import codecs\n",
    "from hanziconv import HanziConv\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dump sql to raw txt\n",
    "conn = sqlite3.connect('apple.sqlite3')\n",
    "cursor = conn.execute(\"SELECT content from apple\")\n",
    "removetokens = [u'翻攝畫面']\n",
    "def get_sentences(c):\n",
    "    i = 0\n",
    "    for w in c:\n",
    "        context = w[0]\n",
    "        context = re.sub(ur'[^\\u4e00-\\u9fff]+', ' ', context)\n",
    "        context = HanziConv.toSimplified(context)\n",
    "        for r in removetokens:\n",
    "            context = re.sub(r, ' ', context)\n",
    "        sentences = context.split(' ')\n",
    "        for s in sentences:\n",
    "            if len(s) > 10:\n",
    "                temp = pseg.cut(s)\n",
    "                words = []\n",
    "                semantics = []\n",
    "                for t in temp:\n",
    "                    words.append(t.word)\n",
    "                    semantics.append(t.flag)\n",
    "                yield '/'.join(words)+ '>>>' + '/'.join(semantics)\n",
    "\n",
    "    c.close()\n",
    "sentences = get_sentences(cursor)\n",
    "with codecs.open('sentences.txt', 'w', encoding='utf8') as f:\n",
    "    for s in sentences:\n",
    "        f.write(s+'\\n')\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract semantic representation\n",
    "with codecs.open('semantics.txt', 'w', encoding='utf8') as g:\n",
    "    with codecs.open('sentences.txt', 'r', encoding='utf8') as f:\n",
    "        for line in f.readlines():\n",
    "            idx = line.rfind('>>>')\n",
    "            target = line[idx + 3:]\n",
    "            g.write(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train word2vec model\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            with open(self.dirname + '/' + fname, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    sen = line[:-1].split('/')\n",
    "                    yield sen\n",
    "\n",
    "# print os.listdir('testdir')\n",
    "sentences = MySentences('testdir')\n",
    "# i = 0\n",
    "# for s in sentences:\n",
    "#     print s\n",
    "#     if i > 10:\n",
    "#         break\n",
    "model = gensim.models.Word2Vec(sentences, window = 5, min_count = 5, size = 30, iter = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "print len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'zg', 'v', 'n', 'vn', 'r']\n",
      "(4, ['vn', 'f', 'rg', 'ud'])\n",
      "---------------------------------------------\n",
      "['v', 'v', 'v', 'uz', 'n', 'p', 'n']\n",
      "(1, ['v', 'zg', 'ag', 'vn'])\n",
      "---------------------------------------------\n",
      "['vn', 'f', 'v', 'v', 'v', 'n']\n",
      "(0, ['vn', 'x', 'vg', 't'])\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# make pseudo cloze quiz for validation\n",
    "import random\n",
    "\n",
    "def make_cloze(num):\n",
    "    gidx = range(0, 20178)\n",
    "    random.shuffle(gidx)\n",
    "    gidx = sorted(set(gidx[: num]))\n",
    "    \n",
    "    curr_idx = 0\n",
    "    sentences = []\n",
    "    with open('testdir/semantics.txt', 'r') as f:\n",
    "        for i in gidx:\n",
    "            for j in xrange(i - curr_idx): f.next()\n",
    "            sentences.append(f.next().split('/')[:-1])\n",
    "            curr_idx = i + 1\n",
    "     \n",
    "    options = []\n",
    "    keys = model.vocab.keys()\n",
    "    for j in xrange(num):\n",
    "        l = len(sentences[j])\n",
    "        if(l <= 0):\n",
    "            print gidx[j]\n",
    "        idx = range(0, 51)\n",
    "        random.shuffle(idx)\n",
    "        \n",
    "        candidate = [keys[i] for i in idx[:3]]\n",
    "#         count = 0\n",
    "#         while count < 10:\n",
    "        i = random.randint(0, l - 1)\n",
    "#             if len(s[i]) > 4 or count == 9:\n",
    "        options.append((i, [sentences[j][i]] + candidate))\n",
    "#                 break\n",
    "#             count += 1\n",
    "    return sentences, options\n",
    "\n",
    "sentences, options = make_cloze(3)\n",
    "for i in xrange(len(sentences)):\n",
    "    print sentences[i]\n",
    "    print options[i]\n",
    "    print '---------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cloze test method\n",
    "def cloze_test(string, index, candidates):\n",
    "    temp = string[:]\n",
    "    del temp[index]\n",
    "    ref_vec = np.zeros(30)\n",
    "    l = 0\n",
    "    for w in temp:\n",
    "        if w in model.vocab:\n",
    "            ref_vec += model[w]\n",
    "        l += 1\n",
    "            \n",
    "#     ref_vec /= float(l)\n",
    "#     ref_vec = ref_vec / np.linalg.norm(ref_vec)\n",
    "    nc = len(candidates)\n",
    "    \n",
    "    arr = np.zeros(nc)\n",
    "    for i in xrange(nc):\n",
    "        if candidates[i] in model.vocab:\n",
    "            cand_vec = model[candidates[i]]\n",
    "#             arr[i] = (ref_vec * cand_vec).sum()\n",
    "            arr[i] = (ref_vec * (cand_vec / np.linalg.norm(cand_vec))).sum()\n",
    "#     l, r = arr[:, j].min(), arr[:, j].max()\n",
    "#     if r > l:\n",
    "#         arr[:, j] = (arr[:, j] - l) / (r - l)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def cal_score(sentences, options):\n",
    "    n = len(sentences)\n",
    "    s = 0.\n",
    "    ref = 0.\n",
    "    for i in xrange(n):\n",
    "#         print sentences[i]\n",
    "#         print options[i][0], options[i][1]\n",
    "        b = cloze_test(sentences[i], options[i][0], options[i][1])\n",
    "        if b.argmax() == 0: s += 1.\n",
    "        if random.randint(0, 3) == 0: ref += 1.\n",
    "    return s/float(n), ref/float(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563 , 0.239\n",
      "0.552 , 0.2605\n",
      "0.5605 , 0.2475\n",
      "0.569 , 0.261\n",
      "0.548 , 0.2655\n",
      "0.5545 , 0.246\n",
      "0.5695 , 0.234\n",
      "0.567 , 0.246\n",
      "0.5535 , 0.2365\n",
      "0.567 , 0.2435\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(10):\n",
    "    sentences, options = make_cloze(2000)\n",
    "    score, ref = cal_score(sentences, options)\n",
    "    print score, ',', ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('w2v_apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s= u'有/在/附近/海域/作业/的/渔民/声称>>>v/p/f/n/n/uj/n/n'\n",
    "# idx = s.rfind('>>>')\n",
    "# t = s[idx + 3:]\n",
    "# print t\n",
    "\n",
    "# string = '越南空軍一架俄羅斯製造的蘇愷'\n",
    "# words = pseg.cut(string)\n",
    "# t = []\n",
    "# for w in words:\n",
    "#     t.append(w.word)\n",
    "# print '/'.join(t)\n",
    "#     print('%s %s' % (w.word, w.flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
